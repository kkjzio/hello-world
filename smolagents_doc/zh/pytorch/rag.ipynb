{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkjzio/hello-world/blob/master/smolagents_doc/zh/pytorch/rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C99fxKkTZTTB",
        "outputId": "cc07caf0-b4b3-4951-f0bb-eeefad1eddb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting smolagents\n",
            "  Downloading smolagents-1.21.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.31.2 in /usr/local/lib/python3.12/dist-packages (from smolagents) (0.34.4)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from smolagents) (2.32.4)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from smolagents) (13.9.4)\n",
            "Requirement already satisfied: jinja2>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from smolagents) (3.1.6)\n",
            "Requirement already satisfied: pillow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from smolagents) (11.3.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from smolagents) (1.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.31.2->smolagents) (1.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.4->smolagents) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.3->smolagents) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->smolagents) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->smolagents) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->smolagents) (0.1.2)\n",
            "Downloading smolagents-1.21.2-py3-none-any.whl (145 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: smolagents\n",
            "Successfully installed smolagents-1.21.2\n"
          ]
        }
      ],
      "source": [
        "# Installation\n",
        "! pip install smolagents\n",
        "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
        "# ! pip install git+https://github.com/huggingface/smolagents.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWPUhG-KZTTF"
      },
      "source": [
        "# Agentic RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpqneNd2ZTTH"
      },
      "source": [
        "Retrieval-Augmented-Generation (RAG) æ˜¯â€œä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ï¼Œä½†åŸºäºä»çŸ¥è¯†åº“ä¸­æ£€ç´¢çš„ä¿¡æ¯â€ã€‚å®ƒæ¯”ä½¿ç”¨æ™®é€šæˆ–å¾®è°ƒçš„ LLM å…·æœ‰è®¸å¤šä¼˜åŠ¿ï¼šä¸¾å‡ ä¸ªä¾‹å­ï¼Œå®ƒå…è®¸å°†ç­”æ¡ˆåŸºäºçœŸå®äº‹å®å¹¶å‡å°‘è™šæ„ï¼›å®ƒå…è®¸æä¾› LLM é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†ï¼›å¹¶å…è®¸å¯¹çŸ¥è¯†åº“ä¸­çš„ä¿¡æ¯è®¿é—®è¿›è¡Œç²¾ç»†æ§åˆ¶ã€‚\n",
        "\n",
        "ä½†æ˜¯ï¼Œæ™®é€šçš„ RAG å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œä»¥ä¸‹ä¸¤ç‚¹å°¤ä¸ºçªå‡ºï¼š\n",
        "\n",
        "- å®ƒåªæ‰§è¡Œä¸€æ¬¡æ£€ç´¢æ­¥éª¤ï¼šå¦‚æœç»“æœä¸å¥½ï¼Œç”Ÿæˆçš„å†…å®¹ä¹Ÿä¼šä¸å¥½ã€‚\n",
        "- è¯­ä¹‰ç›¸ä¼¼æ€§æ˜¯ä»¥ç”¨æˆ·æŸ¥è¯¢ä¸ºå‚è€ƒè®¡ç®—çš„ï¼Œè¿™å¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„ï¼šä¾‹å¦‚ï¼Œç”¨æˆ·æŸ¥è¯¢é€šå¸¸æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œè€ŒåŒ…å«çœŸå®ç­”æ¡ˆçš„æ–‡æ¡£é€šå¸¸æ˜¯è‚¯å®šè¯­æ€ï¼Œå› æ­¤å…¶ç›¸ä¼¼æ€§å¾—åˆ†ä¼šæ¯”å…¶ä»–ä»¥ç–‘é—®å½¢å¼å‘ˆç°çš„æºæ–‡æ¡£ä½ï¼Œä»è€Œå¯¼è‡´é”™å¤±ç›¸å…³ä¿¡æ¯çš„é£é™©ã€‚\n",
        "\n",
        "æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ¶ä½œä¸€ä¸ª RAG  agentæ¥ç¼“è§£è¿™äº›é—®é¢˜ï¼šéå¸¸ç®€å•ï¼Œä¸€ä¸ªé…å¤‡äº†æ£€ç´¢å·¥å…·çš„agentï¼è¿™ä¸ª agent å°†\n",
        "ä¼šï¼šâœ… è‡ªå·±æ„å»ºæŸ¥è¯¢å’Œæ£€ç´¢ï¼Œâœ… å¦‚æœéœ€è¦çš„è¯ä¼šé‡æ–°æ£€ç´¢ã€‚\n",
        "\n",
        "å› æ­¤ï¼Œå®ƒå°†æ¯”æ™®é€š RAG æ›´æ™ºèƒ½ï¼Œå› ä¸ºå®ƒå¯ä»¥è‡ªå·±æ„å»ºæŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨ç”¨æˆ·æŸ¥è¯¢ä½œä¸ºå‚è€ƒã€‚è¿™æ ·ï¼Œå®ƒå¯ä»¥æ›´\n",
        "æ¥è¿‘ç›®æ ‡æ–‡æ¡£ï¼Œä»è€Œæé«˜æ£€ç´¢çš„å‡†ç¡®æ€§ï¼Œ [HyDE](https://huggingface.co/papers/2212.10496)ã€‚æ­¤ agent å¯ä»¥\n",
        "ä½¿ç”¨ç”Ÿæˆçš„ç‰‡æ®µï¼Œå¹¶åœ¨éœ€è¦æ—¶é‡æ–°æ£€ç´¢ï¼Œå°±åƒ [Self-Query](https://docs.llamaindex.ai/en/stable/examples/evaluation/RetryQuery/)ã€‚\n",
        "\n",
        "æˆ‘ä»¬ç°åœ¨å¼€å§‹æ„å»ºè¿™ä¸ªç³»ç»Ÿ. ğŸ› ï¸\n",
        "\n",
        "è¿è¡Œä»¥ä¸‹ä»£ç ä»¥å®‰è£…æ‰€éœ€çš„ä¾èµ–åŒ…ï¼š\n",
        "```bash\n",
        "!pip install smolagents pandas langchain langchain-community sentence-transformers rank_bm25 --upgrade -q\n",
        "```\n",
        "\n",
        "ä½ éœ€è¦ä¸€ä¸ªæœ‰æ•ˆçš„ token ä½œä¸ºç¯å¢ƒå˜é‡ `HF_TOKEN` æ¥è°ƒç”¨ Inference Providersã€‚æˆ‘ä»¬ä½¿ç”¨ python-dotenv æ¥åŠ è½½å®ƒã€‚"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install smolagents pandas langchain langchain-community sentence-transformers rank_bm25 --upgrade -q"
      ],
      "metadata": {
        "id": "lc1sMNVkZqL_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca7sJpHvZTTH",
        "outputId": "89b799c3-9c7f-47ff-e2b4-4f693255942f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ril9ve6aZTTH"
      },
      "source": [
        "æˆ‘ä»¬é¦–å…ˆåŠ è½½ä¸€ä¸ªçŸ¥è¯†åº“ä»¥åœ¨å…¶ä¸Šæ‰§è¡Œ RAGï¼šæ­¤æ•°æ®é›†æ˜¯è®¸å¤š Hugging Face åº“çš„æ–‡æ¡£é¡µé¢çš„æ±‡ç¼–ï¼Œå­˜å‚¨ä¸º markdown æ ¼å¼ã€‚æˆ‘ä»¬å°†ä»…ä¿ç•™ `transformers` åº“çš„æ–‡æ¡£ã€‚ç„¶åé€šè¿‡å¤„ç†æ•°æ®é›†å¹¶å°†å…¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­ï¼Œä¸ºæ£€ç´¢å™¨å‡†å¤‡çŸ¥è¯†åº“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ [LangChain](https://python.langchain.com/docs/introduction/) æ¥åˆ©ç”¨å…¶å‡ºè‰²çš„å‘é‡æ•°æ®åº“å·¥å…·ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1PqfMqXEZTTI"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
        "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
        "\n",
        "source_docs = [\n",
        "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
        "    for doc in knowledge_base\n",
        "]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        "    add_start_index=True,\n",
        "    strip_whitespace=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")\n",
        "docs_processed = text_splitter.split_documents(source_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Pth9s0ZTTI"
      },
      "source": [
        "ç°åœ¨æ–‡æ¡£å·²å‡†å¤‡å¥½ã€‚æˆ‘ä»¬æ¥ä¸€èµ·æ„å»ºæˆ‘ä»¬çš„ agent RAG ç³»ç»Ÿï¼\n",
        "ğŸ‘‰ æˆ‘ä»¬åªéœ€è¦ä¸€ä¸ª RetrieverToolï¼Œæˆ‘ä»¬çš„ agent å¯ä»¥åˆ©ç”¨å®ƒä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ã€‚\n",
        "\n",
        "ç”±äºæˆ‘ä»¬éœ€è¦å°† vectordb æ·»åŠ ä¸ºå·¥å…·çš„å±æ€§ï¼Œæˆ‘ä»¬ä¸èƒ½ç®€å•åœ°ä½¿ç”¨å¸¦æœ‰ `@tool` è£…é¥°å™¨çš„ç®€å•å·¥å…·æ„é€ å‡½æ•°ï¼šå› æ­¤æˆ‘ä»¬å°†éµå¾ª [tools æ•™ç¨‹](https://huggingface.co/docs/smolagents/main/zh/examples/../tutorials/tools) ä¸­çªå‡ºæ˜¾ç¤ºçš„é«˜çº§è®¾ç½®ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JvYDQK68ZTTI"
      },
      "outputs": [],
      "source": [
        "from smolagents import Tool\n",
        "\n",
        "class RetrieverTool(Tool):\n",
        "    name = \"retriever\"\n",
        "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
        "        }\n",
        "    }\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def __init__(self, docs, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.retriever = BM25Retriever.from_documents(\n",
        "            docs, k=10\n",
        "        )\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "\n",
        "        docs = self.retriever.invoke(\n",
        "            query,\n",
        "        )\n",
        "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "            [\n",
        "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
        "                for i, doc in enumerate(docs)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "retriever_tool = RetrieverTool(docs_processed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERa3z-CVZTTI"
      },
      "source": [
        "BM25 æ£€ç´¢æ–¹æ³•æ˜¯ä¸€ä¸ªç»å…¸çš„æ£€ç´¢æ–¹æ³•ï¼Œå› ä¸ºå®ƒçš„è®¾ç½®é€Ÿåº¦éå¸¸å¿«ã€‚ä¸ºäº†æé«˜æ£€ç´¢å‡†ç¡®æ€§ï¼Œä½ å¯ä»¥ä½¿ç”¨è¯­ä¹‰æœç´¢ï¼Œä½¿ç”¨æ–‡æ¡£çš„å‘é‡è¡¨ç¤ºæ›¿æ¢ BM25ï¼šå› æ­¤ä½ å¯ä»¥å‰å¾€ [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) é€‰æ‹©ä¸€ä¸ªå¥½çš„åµŒå…¥æ¨¡å‹ã€‚\n",
        "\n",
        "ç°åœ¨æˆ‘ä»¬å·²ç»åˆ›å»ºäº†ä¸€ä¸ªå¯ä»¥ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯çš„å·¥å…·ï¼Œç°åœ¨æˆ‘ä»¬å¯ä»¥å¾ˆå®¹æ˜“åœ°åˆ›å»ºä¸€ä¸ªåˆ©ç”¨è¿™ä¸ª\n",
        "`retriever_tool` çš„ agentï¼æ­¤ agent å°†ä½¿ç”¨å¦‚ä¸‹å‚æ•°åˆå§‹åŒ–ï¼š\n",
        "- `tools`ï¼šä»£ç†å°†èƒ½å¤Ÿè°ƒç”¨çš„å·¥å…·åˆ—è¡¨ã€‚\n",
        "- `model`ï¼šä¸ºä»£ç†æä¾›åŠ¨åŠ›çš„ LLMã€‚\n",
        "\n",
        "æˆ‘ä»¬çš„ `model` å¿…é¡»æ˜¯ä¸€ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå®ƒæ¥å—ä¸€ä¸ªæ¶ˆæ¯çš„ list ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›æ–‡æœ¬ã€‚å®ƒè¿˜éœ€è¦æ¥å—ä¸€ä¸ª stop_sequences å‚æ•°ï¼ŒæŒ‡ç¤ºä½•æ—¶åœæ­¢ç”Ÿæˆã€‚ä¸ºäº†æ–¹ä¾¿èµ·è§ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨åŒ…ä¸­æä¾›çš„ `HfEngine` ç±»æ¥è·å–è°ƒç”¨ Hugging Face çš„ Inference API çš„ LLM å¼•æ“ã€‚\n",
        "\n",
        "æ¥ç€ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ [meta-llama/Llama-3.3-70B-Instruct](https://huggingface.co/docs/smolagents/main/zh/examples/meta-llama/Llama-3.3-70B-Instruct) ä½œä¸º llm å¼•\n",
        "æ“ï¼Œå› ä¸ºï¼š\n",
        "- å®ƒæœ‰ä¸€ä¸ªé•¿ 128k ä¸Šä¸‹æ–‡ï¼Œè¿™å¯¹å¤„ç†é•¿æºæ–‡æ¡£å¾ˆæœ‰ç”¨ã€‚\n",
        "- å®ƒåœ¨ HF çš„ Inference API ä¸Šå§‹ç»ˆå…è´¹æä¾›ï¼\n",
        "\n",
        "_Note:_ æ­¤ Inference API æ‰˜ç®¡åŸºäºå„ç§æ ‡å‡†çš„æ¨¡å‹ï¼Œéƒ¨ç½²çš„æ¨¡å‹å¯èƒ½ä¼šåœ¨æ²¡æœ‰äº‹å…ˆé€šçŸ¥çš„æƒ…å†µä¸‹è¿›è¡Œæ›´æ–°æˆ–æ›¿æ¢ã€‚äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»[è¿™é‡Œ](https://huggingface.co/docs/api-inference/supported-models)ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "08Oh_WmlZTTI"
      },
      "outputs": [],
      "source": [
        "from smolagents import InferenceClientModel, CodeAgent\n",
        "\n",
        "agent = CodeAgent(\n",
        "    tools=[retriever_tool], model=InferenceClientModel(model_id=\"meta-llama/Llama-3.3-70B-Instruct\"), max_steps=4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8TW5xVZZTTJ"
      },
      "source": [
        "å½“æˆ‘ä»¬åˆå§‹åŒ– CodeAgent æ—¶ï¼Œå®ƒå·²ç»è‡ªåŠ¨è·å¾—äº†ä¸€ä¸ªé»˜è®¤çš„ç³»ç»Ÿæç¤ºï¼Œå‘Šè¯‰ LLM å¼•æ“æŒ‰æ­¥éª¤å¤„ç†å¹¶ç”Ÿæˆå·¥å…·è°ƒç”¨ä½œä¸ºä»£ç ç‰‡æ®µï¼Œä½†ä½ å¯ä»¥æ ¹æ®éœ€è¦æ›¿æ¢æ­¤æç¤ºæ¨¡æ¿ã€‚æ¥ç€ï¼Œå½“å…¶ `.run()` æ–¹æ³•è¢«è°ƒç”¨æ—¶ï¼Œä»£ç†å°†è´Ÿè´£è°ƒç”¨ LLM å¼•æ“ï¼Œå¹¶åœ¨å¾ªç¯ä¸­æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œç›´åˆ°å·¥å…· `final_answer` è¢«è°ƒç”¨ï¼Œè€Œå…¶å‚æ•°ä¸ºæœ€ç»ˆç­”æ¡ˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c-L_4tBqZTTJ",
        "outputId": "bf186d3d-a29a-4cb3-8ed6-59bccf117a0e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;212;183;2mâ•­â”€\u001b[0m\u001b[38;2;212;183;2mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;212;183;2mâ”€â•®\u001b[0m\n",
              "\u001b[38;2;212;183;2mâ”‚\u001b[0m                                                                                                                 \u001b[38;2;212;183;2mâ”‚\u001b[0m\n",
              "\u001b[38;2;212;183;2mâ”‚\u001b[0m \u001b[1mFor a transformers model training, which is slower, the forward or the backward pass?\u001b[0m                           \u001b[38;2;212;183;2mâ”‚\u001b[0m\n",
              "\u001b[38;2;212;183;2mâ”‚\u001b[0m                                                                                                                 \u001b[38;2;212;183;2mâ”‚\u001b[0m\n",
              "\u001b[38;2;212;183;2mâ•°â”€\u001b[0m\u001b[38;2;212;183;2m InferenceClientModel - meta-llama/Llama-3.3-70B-Instruct \u001b[0m\u001b[38;2;212;183;2mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[38;2;212;183;2mâ”€â•¯\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”‚</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”‚</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”‚</span> <span style=\"font-weight: bold\">For a transformers model training, which is slower, the forward or the backward pass?</span>                           <span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”‚</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”‚</span>                                                                                                                 <span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”‚</span>\n",
              "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">â•°â”€ InferenceClientModel - meta-llama/Llama-3.3-70B-Instruct â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;212;183;2mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” \u001b[0m\u001b[1mStep 1\u001b[0m\u001b[38;2;212;183;2m â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” </span><span style=\"font-weight: bold\">Step 1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " â”€ \u001b[1mExecuting parsed code:\u001b[0m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
              "  \u001b[38;2;248;248;242;48;2;39;40;34minfo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretriever\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mcomputational complexity of forward and backward passes in transformers models\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m       \u001b[0m  \n",
              "  \u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34minfo\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m  \n",
              " â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> â”€ <span style=\"font-weight: bold\">Executing parsed code:</span> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
              "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">info </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retriever(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"computational complexity of forward and backward passes in transformers models\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">       </span>  \n",
              "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(info)</span><span style=\"background-color: #272822\">                                                                                                    </span>  \n",
              " â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mExecution logs:\u001b[0m\n",
              "\n",
              "Retrieved documents:\n",
              "\n",
              "\n",
              "===== Document 0 =====\n",
              "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
              "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
              "backward\n",
              "\n",
              "===== Document 1 =====\n",
              "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
              "in \n",
              "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
              "needed \n",
              "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
              "\n",
              "===== Document 2 =====\n",
              "becomes possible to increase the **effective batch size** beyond the limitations imposed by the GPU's memory \n",
              "capacity. \n",
              "However, it is important to note that the additional forward and backward passes introduced by gradient \n",
              "accumulation can \n",
              "slow down the training process.\n",
              "\n",
              "===== Document 3 =====\n",
              "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
              "translates \n",
              "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
              "bandwidth-limited, and itâ€™s typical for an activation to have to read more data in the backward than in the forward\n",
              "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
              "forward,\n",
              "\n",
              "===== Document 4 =====\n",
              "The **gradient accumulation** method aims to calculate gradients in smaller increments instead of computing them \n",
              "for the \n",
              "entire batch at once. This approach involves iteratively calculating gradients in smaller batches by performing \n",
              "forward \n",
              "and backward passes through the model and accumulating the gradients during the process. Once a sufficient number \n",
              "of \n",
              "gradients have been accumulated, the model's optimization step is executed. By employing gradient accumulation, it\n",
              "\n",
              "===== Document 5 =====\n",
              "*Self-attention has become a defacto choice for capturing global context in various vision applications. However, \n",
              "its quadratic computational complexity with respect to image resolution limits its use in real-time applications, \n",
              "especially for deployment on resource-constrained mobile devices\n",
              "\n",
              "===== Document 6 =====\n",
              "`N*K` forward passes through the model are required. This requirement slows inference considerably, particularly as\n",
              "`K` grows.\n",
              "\n",
              "===== Document 7 =====\n",
              "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
              "and returns the updated parameters.\n",
              "\n",
              "===== Document 8 =====\n",
              "## How to benchmark ğŸ¤— Transformers models\n",
              "\n",
              "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark ğŸ¤— Transformers models. \n",
              "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
              "_training_.\n",
              "\n",
              "<Tip>\n",
              "\n",
              "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
              "backward pass.\n",
              "\n",
              "</Tip>\n",
              "\n",
              "===== Document 9 =====\n",
              ". We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and \n",
              "computational costs. Our proposed training techniques help wrangle the instabilities and we show large sparse \n",
              "models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off \n",
              "T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources\n",
              "\n",
              "Out: None\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
              "\n",
              "Retrieved documents:\n",
              "\n",
              "\n",
              "===== Document 0 =====\n",
              "overhead. This is super helpful when you have activation checkpointing enabled, where we do a forward recompute and\n",
              "backward passes a single layer granularity and want to keep the parameter in the forward recompute till the \n",
              "backward\n",
              "\n",
              "===== Document 1 =====\n",
              "Saving all activations from the forward pass in order to compute the gradients during the backward pass can result \n",
              "in \n",
              "significant memory overhead. The alternative approach of discarding the activations and recalculating them when \n",
              "needed \n",
              "during the backward pass, would introduce a considerable computational overhead and slow down the training process.\n",
              "\n",
              "===== Document 2 =====\n",
              "becomes possible to increase the **effective batch size** beyond the limitations imposed by the GPU's memory \n",
              "capacity. \n",
              "However, it is important to note that the additional forward and backward passes introduced by gradient \n",
              "accumulation can \n",
              "slow down the training process.\n",
              "\n",
              "===== Document 3 =====\n",
              "For convolutions and linear layers there are 2x flops in the backward compared to the forward, which generally \n",
              "translates \n",
              "into ~2x slower (sometimes more, because sizes in the backward tend to be more awkward). Activations are usually \n",
              "bandwidth-limited, and itâ€™s typical for an activation to have to read more data in the backward than in the forward\n",
              "(e.g. activation forward reads once, writes once, activation backward reads twice, gradOutput and output of the \n",
              "forward,\n",
              "\n",
              "===== Document 4 =====\n",
              "The **gradient accumulation** method aims to calculate gradients in smaller increments instead of computing them \n",
              "for the \n",
              "entire batch at once. This approach involves iteratively calculating gradients in smaller batches by performing \n",
              "forward \n",
              "and backward passes through the model and accumulating the gradients during the process. Once a sufficient number \n",
              "of \n",
              "gradients have been accumulated, the model's optimization step is executed. By employing gradient accumulation, it\n",
              "\n",
              "===== Document 5 =====\n",
              "*Self-attention has become a defacto choice for capturing global context in various vision applications. However, \n",
              "its quadratic computational complexity with respect to image resolution limits its use in real-time applications, \n",
              "especially for deployment on resource-constrained mobile devices\n",
              "\n",
              "===== Document 6 =====\n",
              "`N*K` forward passes through the model are required. This requirement slows inference considerably, particularly as\n",
              "`K` grows.\n",
              "\n",
              "===== Document 7 =====\n",
              "- A train step function which combines the loss function and optimizer update, does the forward and backward pass \n",
              "and returns the updated parameters.\n",
              "\n",
              "===== Document 8 =====\n",
              "## How to benchmark ğŸ¤— Transformers models\n",
              "\n",
              "The classes [`PyTorchBenchmark`] and [`TensorFlowBenchmark`] allow to flexibly benchmark ğŸ¤— Transformers models. \n",
              "The benchmark classes allow us to measure the _peak memory usage_ and _required time_ for both _inference_ and \n",
              "_training_.\n",
              "\n",
              "&lt;Tip&gt;\n",
              "\n",
              "Hereby, _inference_ is defined by a single forward pass, and _training_ is defined by a single forward pass and\n",
              "backward pass.\n",
              "\n",
              "&lt;/Tip&gt;\n",
              "\n",
              "===== Document 9 =====\n",
              ". We simplify the MoE routing algorithm and design intuitive improved models with reduced communication and \n",
              "computational costs. Our proposed training techniques help wrangle the instabilities and we show large sparse \n",
              "models may be trained, for the first time, with lower precision (bfloat16) formats. We design models based off \n",
              "T5-Base and T5-Large to obtain up to 7x increases in pre-training speed with the same computational resources\n",
              "\n",
              "Out: None\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2m[Step 1: Duration 2.08 seconds| Input tokens: 2,001 | Output tokens: 110]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 2.08 seconds| Input tokens: 2,001 | Output tokens: 110]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;212;183;2mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” \u001b[0m\u001b[1mStep 2\u001b[0m\u001b[38;2;212;183;2m â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” </span><span style=\"font-weight: bold\">Step 2</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              " â”€ \u001b[1mExecuting parsed code:\u001b[0m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
              "  \u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbackward pass\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m  \n",
              " â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> â”€ <span style=\"font-weight: bold\">Executing parsed code:</span> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
              "  <span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"backward pass\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                  </span>  \n",
              " â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;38;2;212;183;2mFinal answer: backward pass\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Final answer: backward pass</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[2m[Step 2: Duration 1.64 seconds| Input tokens: 4,880 | Output tokens: 217]\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 2: Duration 1.64 seconds| Input tokens: 4,880 | Output tokens: 217]</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final output:\n",
            "backward pass\n"
          ]
        }
      ],
      "source": [
        "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
        "\n",
        "print(\"Final output:\")\n",
        "print(agent_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}